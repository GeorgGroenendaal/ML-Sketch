{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions to work with svg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for draw_strokes\n",
    "def get_bounds(data, factor):\n",
    "  min_x = 0\n",
    "  max_x = 0\n",
    "  min_y = 0\n",
    "  max_y = 0\n",
    "    \n",
    "  abs_x = 0\n",
    "  abs_y = 0\n",
    "  for i in xrange(len(data)):\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    abs_x += x\n",
    "    abs_y += y\n",
    "    min_x = min(min_x, abs_x)\n",
    "    min_y = min(min_y, abs_y)\n",
    "    max_x = max(max_x, abs_x)\n",
    "    max_y = max(max_y, abs_y)\n",
    "    \n",
    "  return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=2, svg_filename = 'sample.svg'):\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(0,20):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"red\"\n",
    "  stroke_width = 2\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  for i in xrange(20,len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=15.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)\n",
    "#test_set = np.load(data_dir, encoding='latin1', allow_pickle=True)\n",
    "# get a sample drawing from the test set, and render it to .svg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"218.5\" version=\"1.1\" width=\"353.5\"><defs/><rect fill=\"white\" height=\"218.5\" width=\"353.5\" x=\"0\" y=\"0\"/><path d=\"M59.0,79.5 m0.0,-10.5 l5.0,-12.5 17.5,-15.0 l18.0,-10.0 15.5,0.0 l13.5,5.5 9.0,10.0 l2.0,5.0 14.0,-16.0 l7.5,-5.0 11.5,-6.0 l10.0,0.0 12.0,4.0 l5.0,3.5 11.5,20.0 l5.5,-2.5 14.5,-11.5 l16.0,-8.5 14.0,-5.0 l15.0,0.0 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M59.0,79.5 m0.0,-10.5 l5.0,-12.5 17.5,-15.0 l18.0,-10.0 15.5,0.0 l13.5,5.5 9.0,10.0 l2.0,5.0 14.0,-16.0 l7.5,-5.0 11.5,-6.0 l10.0,0.0 12.0,4.0 l5.0,3.5 11.5,20.0 l5.5,-2.5 14.5,-11.5 l16.0,-8.5 14.0,-5.0 l15.0,0.0 14.5,4.0 l16.5,9.5 5.5,8.0 l3.0,11.0 -1.0,9.5 l-3.0,5.5 -10.0,10.0 l9.5,1.0 11.0,7.5 l6.0,11.5 0.5,9.5 l-3.5,16.0 -9.5,17.0 l-4.0,5.5 -23.0,15.5 l-11.0,4.0 -15.5,2.0 l-20.0,-2.5 -4.5,-2.0 l-12.0,-9.0 -9.5,-16.5 l-2.0,0.0 -21.0,23.0 l-19.5,16.0 -17.5,8.5 l-17.0,4.0 -11.0,0.0 l-19.5,-5.5 -16.0,-10.5 l-12.0,-14.0 -4.5,-10.0 l-2.0,-9.5 -6.0,10.5 l-4.5,4.0 -9.5,3.0 l-13.5,-2.0 -6.0,-3.5 l-7.5,-9.5 -2.0,-9.0 l1.0,-10.0 8.5,-17.5 l7.0,-10.0 15.5,-16.0 l14.5,-11.5 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Focus on cloud for the begining\n",
    "data_dir = 'cloud.npz'\n",
    "\n",
    "load_data = np.load(data_dir, encoding='latin1', allow_pickle=True) #specific to python3\n",
    "train_set = load_data['train']\n",
    "valid_set = load_data['valid']\n",
    "test_set = load_data['test']\n",
    "\n",
    "print (len(train_set))\n",
    "print (len(valid_set))\n",
    "print (len(test_set))\n",
    "\n",
    "draw_strokes(random.choice(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_window(input_data: np.array, window_size: int) -> np.array:\n",
    "    data_len = len(input_data)\n",
    "    result = np.zeros((data_len-window_size+1, window_size, *input_data.shape[1:]))\n",
    "    for i in range(data_len):\n",
    "        if i+window_size <= data_len:\n",
    "            result[i] = input_data[i:i+window_size]\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_window_on_multiple_samples(input_data: np.array, window_size: int, normalized = False) -> np.array:\n",
    "    \"\"\"\n",
    "    Similar to create_window, but now can take multiple samples, will output in one\n",
    "    giant windowed np.array.\n",
    "    \"\"\"\n",
    "    windowed_data = []\n",
    "    scaler = MinMaxScaler()\n",
    "    for i, sample in enumerate(input_data):\n",
    "        win = create_window(sample[:,:2], window_size)\n",
    "        \n",
    "        # Normalize the data\n",
    "        if normalized:\n",
    "            win = normalise_windows(win)\n",
    "            \n",
    "        windowed_data.append(win)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Now at {i}\")\n",
    "            clear_output(wait=True)\n",
    "    result = np.concatenate(windowed_data)\n",
    "#     print(f\"result = {result} \\t winddata = {windowed_data}\")\n",
    "    print(f\"Done processing {i} samples, total of {result.shape[0]} windows and {result.shape[0] * result.shape[1]} datapoints\")\n",
    "    return np.concatenate(result)\n",
    "\n",
    "\n",
    "def split_train_test(input_data: List) -> Tuple[np.array, np.array]:\n",
    "    return input_data[:,:-1], input_data[:,-1]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    # A support function to normalize a dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        scaled = scaler.fit_transform(window)\n",
    "        normalised_data.append(scaled)\n",
    "    return np.concatenate(normalised_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing 499 samples, total of 186704 windows and 373408 datapoints\n"
     ]
    }
   ],
   "source": [
    "x = create_window_on_multiple_samples(train_set[:500], 7, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f89df7df9d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X = np.asarray(X).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Y = np.asarray(Y).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d976d2fa75ee>\u001b[0m in \u001b[0;36msplit_train_test\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalise_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# x\n",
    "X, Y = split_train_test(x)\n",
    "# X\n",
    "# X = np.asarray(X).astype('float32')\n",
    "# Y = np.asarray(Y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Initialize LSTM\n",
    "model = Sequential()\n",
    "# print (train_set[3].shape)\n",
    "model.add(LSTM(units=50, return_sequences=True,\n",
    "     input_shape=(X.shape[0], 2)))\n",
    "\n",
    "# Adding a second LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # Adding a fourth LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\n",
    "print(model.summary())\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs = 200)\n",
    "# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LSTM model\n",
    "# history = model.fit(X, Y, epochs = 100, batch_size = 50, verbose = 1)\n",
    "# plt.figure()\n",
    "# plt.ylabel('loss'); plt.xlabel('epoch')\n",
    "plt.semilogy(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X= np.empty([0,S_reg*3])\n",
    "# line= np.array([])\n",
    "# Y=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #warning: x goes into floating...\n",
    "# for data in test_set:\n",
    "#     i=20\n",
    "#     while i <= (len(data)-1):\n",
    "#         line= np.array([])\n",
    "#         for j in range (S_reg):\n",
    "#             line = np.concatenate((line, data[i-S_reg+j]), 0)\n",
    "#         #print(X,line)\n",
    "#         X = np.vstack((X, line))\n",
    "#         Y = np.concatenate((Y, data[i]), 0) #to change\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=Y.reshape((int(len(Y)/3), 3)) #to change\n",
    "# X=X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv=np.linalg.inv(np.dot(X,X.T)+0.01*np.identity(S_reg*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W=np.dot(np.dot(inv,X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test in range (0,100):\n",
    "#     ini=np.array([])\n",
    "#     for i in range(20):\n",
    "#         ini=np.concatenate((ini, train_set[test][i]), 0)\n",
    "#     draw=train_set[test][0:20]\n",
    "#     for i in range (300):\n",
    "#         draw=np.vstack((draw, np.dot(W.T,ini)))\n",
    "#         ini=np.concatenate((ini, draw[-1]), 0)\n",
    "#         ini = np.delete(ini, [0,1,2])\n",
    "#     draw[:, 2]=0 # I do not take into account the different strokes\n",
    "#     draw_strokes(draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echo State network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for count,sample in enumerate(train_set[0:2500]):\n",
    "#     if count==0:\n",
    "#         X_train=sample\n",
    "#     else:\n",
    "#         X_train = np.vstack((X_train,sample))\n",
    "#     train_set[count]=np.tanh(np.delete(sample, 2, axis=1)/100) #trick for not caring about different strokes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data \n",
    "# in \"plain\" scientific Python.\n",
    "# from https://mantas.info/code/simple_esn/\n",
    "# (c) 2012-2020 Mantas LukoÅ¡eviÄius\n",
    "# Distributed under MIT license https://opensource.org/licenses/MIT\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import linalg \n",
    "# # numpy.linalg is also an option for even fewer dependencies\n",
    "\n",
    "# # load the data\n",
    "# data = train_set[0:2000]\n",
    "# trainLen = len(X_train) \n",
    "# testLen = len(X_train) \n",
    "# initLen = 0 #Warning higly reduced\n",
    "\n",
    "\n",
    "# # generate the ESN reservoir\n",
    "# inSize = outSize = 2\n",
    "# resSize = 1000\n",
    "# L_a = [0.3,1,5] # leaking rate\n",
    "# np.random.seed(42)\n",
    "# L_Win = [(np.random.rand(resSize,1+inSize) - 0.5) *i for i in [0.1,1,2]]\n",
    "# label_Win = [0.1,1,2]\n",
    "\n",
    "# W = np.random.rand(resSize,resSize) - 0.5 \n",
    "# # normalizing and setting spectral radius (correct, slow):\n",
    "# print('Computing spectral radius...')\n",
    "# rhoW = max(abs(linalg.eig(W)[0]))\n",
    "# print('done.')\n",
    "# L_W = [W*i / rhoW for i in [0.75,1,1.25]]\n",
    "# label_W = [0.75,1,1.5]\n",
    "\n",
    "# # allocated memory for the design (collected states) matrix\n",
    "# X = np.zeros((1+inSize+resSize,trainLen-(initLen+1)*len(data)))\n",
    "# Yt = np.zeros((outSize,trainLen-(initLen+1)*len(data)))\n",
    "\n",
    "# # set the corresponding target matrix directly\n",
    "# #Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# print(\"run reservoir\")\n",
    "# L_XXT=[]\n",
    "# L_XYT=[]\n",
    "# # run the reservoir with the data and collect X\n",
    "# i=0\n",
    "# for W in L_W:\n",
    "#      for Win in L_Win:\n",
    "#         for a in L_a:\n",
    "#             i+=1\n",
    "#             print(i)\n",
    "#             # allocated memory for the design (collected states) matrix\n",
    "#             X = np.zeros((1+inSize+resSize,trainLen-(initLen+1)*len(data)))\n",
    "#             Yt = np.zeros((outSize,trainLen-(initLen+1)*len(data)))\n",
    "#             for sample in data:\n",
    "#                 x = np.zeros((resSize,1))\n",
    "#                 count_global=0\n",
    "#                 for count,u in enumerate(sample):\n",
    "#                     u=np.array([u]).T\n",
    "#                     #print(np.vstack((1,u)))\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     if count >= initLen:\n",
    "#                         count_global += 1\n",
    "#                         X[:,count_global] = np.vstack((1,u,x))[:,0]\n",
    "#                         if count >= initLen+1:\n",
    "#                             Yt[:,count_global-1] = np.vstack((u))[:,0]\n",
    "#                     if count == len(sample)-2:\n",
    "#                         Yt[:,count_global-1] = np.vstack((u))[:,0]\n",
    "#                         break\n",
    "#             L_XXT.append(np.dot(X,X.T))\n",
    "#             L_XYT.append(np.dot(X,Yt.T))\n",
    "                \n",
    "# print(\"train reservoir\")\n",
    "# # train the output by ridge regression\n",
    "# Wout_list=[]\n",
    "# count=0\n",
    "# for w,W in zip(label_W,L_W):\n",
    "#     for win,Win in zip(label_Win,L_Win):\n",
    "#         for a in L_a:\n",
    "#             XXT=L_XXT[count]\n",
    "#             XYT=L_XYT[count]\n",
    "#             count=+1\n",
    "#             for i in range(8):\n",
    "#                 reg = 1^-i  # regularization coefficient\n",
    "#                 # direct equations from texts:\n",
    "#                 #X_T = X.T\n",
    "#                 #Wout = np.dot( np.dot(Yt,X_T), linalg.inv( np.dot(X,X_T) + \\\n",
    "#                 #    reg*np.eye(1+inSize+resSize) ) )\n",
    "#                 # using scipy.linalg.solve:\n",
    "#                 Wout = linalg.solve( XXT + reg*np.eye(1+inSize+resSize), \n",
    "#                     XYT ).T\n",
    "#                 Wout_list.append([Wout,W,str(w),Win,str(win),a,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"Nz1000_data2000_norm.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Wout_list, fp)\n",
    "\n",
    "with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Wout_list = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import linalg as LA\n",
    "# L_mse=[]\n",
    "\n",
    "# for count,Wout in enumerate(Wout_list):\n",
    "#     Wout,W,w,Win,win,a,i=Wout\n",
    "#     for number in range (500):\n",
    "#         Y = np.zeros((outSize, len(data[number])))\n",
    "#         X = np.zeros((resSize, len(data[number])))\n",
    "#         u = np.array([data[number][0]]).T\n",
    "#         x = np.zeros((resSize,1))\n",
    "#         mse_ini=0\n",
    "#         mse_fill=0\n",
    "#         for t in range(len(data[number])):\n",
    "#             if t <= 15:\n",
    "#                 u = np.array([data[number][t]]).T\n",
    "#                 x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                 y = np.dot(Wout, np.vstack((1,u,x)))\n",
    "#                 #y=np.array([y]).T\n",
    "#                 Y[:,t] = y[:,0]\n",
    "#                 mse_ini += LA.norm(y[:,0]-data[number][t+1])\n",
    "#             else:\n",
    "#                 x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                 y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#                 u = y\n",
    "#                 #print(y)\n",
    "#                 #y=np.array([y]).T\n",
    "#                 Y[:,t] = y[:,0]\n",
    "#                 # generative mode:\n",
    "#                 if t < len(data[number])-2:\n",
    "#                     mse_fill += LA.norm(y[:,0]-data[number][t+1])\n",
    "#             X[:,t]=np.array([x]).T[:,0]\n",
    "\n",
    "            \n",
    "#         mse_ini = mse_ini/(15)\n",
    "#         mse_fill = mse_fill/len(data[number]-15)\n",
    "\n",
    "#         row = {'mse_ini' : mse_ini, 'mse_fill' : mse_fill, 'w' : float(w), 'win' : float(win),'a' : float(a),'i' : float(i),'number' : number}\n",
    "#     L_mse.append(row)       \n",
    "# df = pd.DataFrame(L_mse)\n",
    "# df.to_pickle(\"mse(Nz1000_data2000_norm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To plot\n",
    "# for count,Wout in enumerate(Wout_list):\n",
    "#     Wout,W,w,Win,win,a,i=Wout\n",
    "#     if (w==str(1.50)) & (win==str(2)) & (a==1) & (i==3.0):\n",
    "#         for number in range (0,5):\n",
    "#             Y = np.zeros((outSize, len(data[number])))\n",
    "#             X = np.zeros((resSize, len(data[number])))\n",
    "#             u = np.array([data[number][0]]).T\n",
    "#             x = np.zeros((resSize,1))\n",
    "#             mse_ini=0\n",
    "#             mse_fill=0\n",
    "#             for t in range(len(data[number])):\n",
    "#                 if t <= 20:\n",
    "#                     u = np.array([data[number][t]]).T\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     y = np.dot(Wout, np.vstack((1,u,x)))\n",
    "#                     #y=np.array([y]).T\n",
    "#                     Y[:,t] = y[:,0]\n",
    "#                     mse_ini += LA.norm(y[:,0]-data[number][t+1])\n",
    "#                 else:\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#                     u = y\n",
    "\n",
    "#                     Y[:,t] = y[:,0]\n",
    "#                     # generative mode:\n",
    "#                     if t < len(data[number])-2:\n",
    "#                         mse_fill += LA.norm(y[:,0]-data[number][t+1])\n",
    "#                 X[:,t]=np.array([x]).T[:,0]\n",
    "                \n",
    "#             N = 2\n",
    "#             b = np.zeros((len(data[number]),N+1))\n",
    "#             b[:,:-1] = Y.T\n",
    "#             #print(Y.T)\n",
    "#             #print(b)\n",
    "#             draw_strokes(b,factor=2,svg_filename = str(number)+'sample.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         N = 2\n",
    "#         a = np.random.rand(N,N)\n",
    "#         b = np.zeros((N,N+1))\n",
    "#         b[:,:-1] = a\n",
    "#         b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_strokes(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data \n",
    "# in \"plain\" scientific Python.\n",
    "# from https://mantas.info/code/simple_esn/\n",
    "# (c) 2012-2020 Mantas LukoÅ¡eviÄius\n",
    "# Distributed under MIT license https://opensource.org/licenses/MIT\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import linalg \n",
    "# # numpy.linalg is also an option for even fewer dependencies\n",
    "\n",
    "# # load the data\n",
    "# trainLen = 2000\n",
    "# testLen = 2000\n",
    "# initLen = 100\n",
    "# data = np.loadtxt('MackeyGlass_t17.txt')\n",
    "\n",
    "# # plot some of it\n",
    "# plt.figure(10).clear()\n",
    "# plt.plot(data[:1000])\n",
    "# plt.title('A sample of data')\n",
    "\n",
    "# # generate the ESN reservoir\n",
    "# inSize = outSize = 1\n",
    "# resSize = 1000\n",
    "# a = 0.3 # leaking rate\n",
    "# np.random.seed(42)\n",
    "# Win = (np.random.rand(resSize,1+inSize) - 0.5) * 1\n",
    "# W = np.random.rand(resSize,resSize) - 0.5 \n",
    "# # normalizing and setting spectral radius (correct, slow):\n",
    "# print('Computing spectral radius...')\n",
    "# rhoW = max(abs(linalg.eig(W)[0]))\n",
    "# print('done.')\n",
    "# W *= 1.25 / rhoW\n",
    "\n",
    "# # allocated memory for the design (collected states) matrix\n",
    "# X = np.zeros((1+inSize+resSize,trainLen-initLen))\n",
    "# # set the corresponding target matrix directly\n",
    "# Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# # run the reservoir with the data and collect X\n",
    "# x = np.zeros((resSize,1))\n",
    "# for t in range(trainLen):\n",
    "#     u = data[t]\n",
    "#     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#     if t >= initLen:\n",
    "#         X[:,t-initLen] = np.vstack((1,u,x))[:,0]\n",
    "    \n",
    "# # train the output by ridge regression\n",
    "# reg = 1e-8  # regularization coefficient\n",
    "# # direct equations from texts:\n",
    "# #X_T = X.T\n",
    "# #Wout = np.dot( np.dot(Yt,X_T), linalg.inv( np.dot(X,X_T) + \\\n",
    "# #    reg*np.eye(1+inSize+resSize) ) )\n",
    "# # using scipy.linalg.solve:\n",
    "# Wout = linalg.solve( np.dot(X,X.T) + reg*np.eye(1+inSize+resSize), \n",
    "#     np.dot(X,Yt.T) ).T\n",
    "\n",
    "# # run the trained ESN in a generative mode. no need to initialize here, \n",
    "# # because x is initialized with training data and we continue from there.\n",
    "# Y = np.zeros((outSize,testLen))\n",
    "# u = data[trainLen]\n",
    "# for t in range(testLen):\n",
    "#     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#     y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#     Y[:,t] = y\n",
    "#     # generative mode:\n",
    "#     u = y\n",
    "#     ## this would be a predictive mode:\n",
    "#     #u = data[trainLen+t+1] \n",
    "\n",
    "# # compute MSE for the first errorLen time steps\n",
    "# errorLen = 500\n",
    "# mse = sum( np.square( data[trainLen+1:trainLen+errorLen+1] - \n",
    "#     Y[0,0:errorLen] ) ) / errorLen\n",
    "# print('MSE = ' + str( mse ))\n",
    "    \n",
    "# # plot some signals\n",
    "# plt.figure(1).clear()\n",
    "# plt.plot( data[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "# plt.plot( Y.T, 'b' )\n",
    "# plt.title('Target and generated signals $y(n)$ starting at $n=0$')\n",
    "# plt.legend(['Target signal', 'Free-running predicted signal'])\n",
    "\n",
    "# plt.figure(2).clear()\n",
    "# plt.plot( X[0:20,0:200].T )\n",
    "# plt.title(r'Some reservoir activations $\\mathbf{x}(n)$')\n",
    "\n",
    "# plt.figure(3).clear()\n",
    "# plt.bar( np.arange(1+inSize+resSize), Wout[0].T )\n",
    "# plt.title(r'Output weights $\\mathbf{W}^{out}$')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_i=df\n",
    "# df_i= df.groupby(['w','win','a',\"i\"])['mse_fill'].mean().reset_index()\n",
    "# df_i[df_i.mse_fill<0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=300)\n",
    "# ax = fig.gca(projection='3d')\n",
    "# for i in range (8):\n",
    "\n",
    "#     df_i=df[df.i == i ]\n",
    "#     df_i= df_i.groupby(['w','win','a'])['mse_fill'].mean().reset_index()\n",
    "#     xs = list(df_i['w'])\n",
    "#     ys = list(df_i['win']+0.05*i)\n",
    "#     zs = list(df_i['a'])\n",
    "#     ss = list(df_i['mse_fill'])\n",
    "#     #print(xs)\n",
    "    \n",
    "#     ax.set_xlabel('w')\n",
    "#     ax.set_ylabel('win')\n",
    "#     ax.set_zlabel('a')\n",
    "\n",
    "#     surf=ax.scatter3D(xs, ys, zs, c=ss,vmin=0,vmax=0.5,s=20)#, lw=0, s=100,alpha=1,marker=\"o\",vmin=vmin,vmax=vmax)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "# plt.show()\n",
    "# plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212.003px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

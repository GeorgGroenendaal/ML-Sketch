{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils import create_window,split_train_test\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to draw data\n",
    "\n",
    "- In draw_strokes(), the first 20 data points are written in black and the rest of the data is drawn in brown. This value(20) is a constant, which can be varied for further experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for draw_strokes\n",
    "def get_bounds(data, factor):\n",
    "    min_x = 0\n",
    "    max_x = 0\n",
    "    min_y = 0\n",
    "    max_y = 0\n",
    "\n",
    "    abs_x = 0\n",
    "    abs_y = 0\n",
    "    for i in xrange(len(data)):\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        abs_x += x\n",
    "        abs_y += y\n",
    "        min_x = min(min_x, abs_x)\n",
    "        min_y = min(min_y, abs_y)\n",
    "        max_x = max(max_x, abs_x)\n",
    "        max_y = max(max_y, abs_y)\n",
    "    \n",
    "    return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=2, svg_filename = 'sample.svg'):\n",
    "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "    lift_pen = 1\n",
    "    abs_x = 25 - min_x \n",
    "    abs_y = 25 - min_y\n",
    "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "    command = \"m\"\n",
    "    for i in xrange(0,20):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command+str(x)+\",\"+str(y)+\" \"\n",
    "    the_color = \"red\"\n",
    "    stroke_width = 2\n",
    "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "    for i in xrange(20,len(data)):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command+str(x)+\",\"+str(y)+\" \"\n",
    "    the_color = \"black\"\n",
    "    stroke_width = 1\n",
    "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "    dwg.save()\n",
    "    display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=15.0):\n",
    "    \n",
    "    def get_start_and_end(x):\n",
    "        x = np.array(x)\n",
    "        x = x[:, 0:2]\n",
    "        x_start = x[0]\n",
    "        x_end = x.sum(axis=0)\n",
    "        x = x.cumsum(axis=0)\n",
    "        x_max = x.max(axis=0)\n",
    "        x_min = x.min(axis=0)\n",
    "        center_loc = (x_max+x_min)*0.5\n",
    "        return x_start-center_loc, x_end\n",
    "  \n",
    "    x_pos = 0.0\n",
    "    y_pos = 0.0\n",
    "    result = [[x_pos, y_pos, 1]]\n",
    "    \n",
    "    for sample in s_list:\n",
    "        s = sample[0]\n",
    "        grid_loc = sample[1]\n",
    "        grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "        grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "        start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "        loc_x = start_loc[0]\n",
    "        loc_y = start_loc[1]\n",
    "        new_x_pos = grid_x+loc_x\n",
    "        new_y_pos = grid_y+loc_y\n",
    "        result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "        result += s.tolist()\n",
    "        result[-1][2] = 1\n",
    "        x_pos = new_x_pos+delta_pos[0]\n",
    "        y_pos = new_y_pos+delta_pos[1]\n",
    "    return np.array(result)\n",
    "#test_set = np.load(data_dir, encoding='latin1', allow_pickle=True)\n",
    "# get a sample drawing from the test set, and render it to .svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"192.5\" version=\"1.1\" width=\"273.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"192.5\" width=\"273.5\" x=\"0\" y=\"0\"/><path d=\"M66.0,36.5 m15.5,-11.0 l5.5,-0.5 21.0,11.5 l5.0,5.0 1.0,15.5 l35.5,-4.0 18.0,0.5 l7.5,5.0 5.5,6.0 l2.0,14.5 -1.0,3.5 l5.0,3.5 34.5,8.5 l11.5,1.0 11.0,5.0 l5.0,9.5 0.0,8.0 l-1.0,6.5 -4.0,8.0 l0.0,6.5 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M66.0,36.5 m15.5,-11.0 l5.5,-0.5 21.0,11.5 l5.0,5.0 1.0,15.5 l35.5,-4.0 18.0,0.5 l7.5,5.0 5.5,6.0 l2.0,14.5 -1.0,3.5 l5.0,3.5 34.5,8.5 l11.5,1.0 11.0,5.0 l5.0,9.5 0.0,8.0 l-1.0,6.5 -4.0,8.0 l0.0,6.5 -2.0,5.5 l-5.5,5.0 -14.0,5.5 l-20.5,2.5 -11.0,-5.0 l-1.0,-3.5 -5.5,5.5 l-21.5,9.0 -22.5,4.0 l-14.0,0.0 -1.5,-2.5 l0.0,-25.0 -3.5,-1.5 l-10.0,2.0 -15.5,-0.5 l-4.0,-4.5 -2.0,-6.5 l0.5,-10.5 -2.5,-2.0 l-20.0,2.5 -4.5,-1.5 l-5.5,-13.0 0.0,-3.5 l-25.5,-9.5 -7.0,-4.5 l0.0,-5.5 8.0,-17.5 l-5.0,-6.0 -2.0,-9.5 l0.5,-7.0 6.0,-8.5 l3.0,-0.5 5.0,5.5 l3.5,0.5 13.5,-9.5 l1.0,4.0 3.0,2.5 l5.5,0.5 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = 'cloud.npz'\n",
    "load_data = np.load(data_dir, encoding='latin1', allow_pickle=True) #specific to python3\n",
    "train_set = load_data['train']\n",
    "valid_set = load_data['valid']\n",
    "test_set = load_data['test']\n",
    "\n",
    "print (len(train_set))\n",
    "print (len(valid_set))\n",
    "print (len(test_set))\n",
    "\n",
    "draw_strokes(random.choice(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the data\n",
    "\n",
    "- each data in the train set is a 2 dimensional numpyarray with 3 values (x_pixel,y_pixel,[penup=1,pendown=0])\n",
    "- The following steps are done for all samples in the train set\n",
    "    - we take each sample from the train set\n",
    "    - create windows of length 20 [create_window() is written by George]\n",
    "    - save a set of 20 points as train_X\n",
    "    - save the corresponding 21st point from the set as the value to predict i.e train_y\n",
    "    - iterate through the entire sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: it takes a long time to fit the model on the entire data\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(len(train_set)-1):\n",
    "    all_windows = create_window(train_set[i],20)\n",
    "    for j in range(len(all_windows)-1):\n",
    "        \n",
    "        X,y = all_windows[j],all_windows[j+1][-1]\n",
    "        train_X.append(X)\n",
    "        train_y.append(y)\n",
    "    if(i==50000):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X)\n",
    "nsamples,nx,ny = train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since scikit learn requires data with a maximum of 2 dimensions we reshape it (flatten it)\n",
    "# reshaped data with dimensions = 2\n",
    "d2_train_dataset = train_X.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1., -42.,   0.,   5., -10.,   0.,  28., -21.,   0.,  29.,  -8.,   0.,  47.,   1.,   0.,  19.,  10.,   0.,   2.,  12.,   0., -11.,  15.,   0.,  10.,   2.,   0.,  92.,  -5.,   0., 137.,   0.,\n",
       "         0.,   3.,   5.,   0.,  -7.,   3.,   0., -16.,  17.,   0., 130.,  -1.,   0.,   6.,   5.,   0.,  -1.,  13.,   0.,  -4.,   9.,   0., -22.,  22.,   0.,  50.,  -4.,   0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "- Here we use a Random forest regressor with the intuition being to pass a regression line\n",
    "- The number of estimators=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomForestRegressor model with the required parameters - \n",
    "# 1) number of decision trees required (n_estimators)\n",
    "# 2) The maximum depth of the tree (max_depth)\n",
    "# 3) The criteria to measure quality of split (criterion=\"mse\" for variance reduction as suggested by Brieman since we have continous data)\n",
    "#  \n",
    "model = RandomForestRegressor(n_estimators=10,max_depth=10,criterion=\"mse\")\n",
    "\n",
    "#Fit the training data (reshaped training data,y)\n",
    "model.fit(d2_train_dataset, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model/RF_n10_trained.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "After obtaining a test sample, the following is performed\n",
    "- reshape the test sample to match the training data\n",
    "- Since our predicts only the next point in the sequence, we append the result each time to the original test sample.\n",
    "- After appending we predict on the latest 20 points and repeat these steps for 100 times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/RF_n10.sav'\n",
    "nx=20\n",
    "ny=3\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"200.5\" version=\"1.1\" width=\"331.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"200.5\" width=\"331.5\" x=\"0\" y=\"0\"/><path d=\"M73.0,33.5 m-17.0,-8.5 l-15.0,0.0 -5.5,8.5 l-1.5,18.5 8.0,12.0 l7.0,5.0 5.5,1.5 l-2.0,17.0 0.0,9.0 l2.0,3.0 22.0,7.5 l13.0,0.0 4.5,-4.5 l2.0,-5.5 14.0,10.5 l13.5,4.5 9.0,0.5 l30.0,-5.5 4.5,-1.5 l3.0,-14.5 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M73.0,33.5 m-17.0,-8.5 l-15.0,0.0 -5.5,8.5 l-1.5,18.5 8.0,12.0 l7.0,5.0 5.5,1.5 l-2.0,17.0 0.0,9.0 l2.0,3.0 22.0,7.5 l13.0,0.0 4.5,-4.5 l2.0,-5.5 14.0,10.5 l13.5,4.5 9.0,0.5 l30.0,-5.5 4.5,-1.5 l3.0,-14.5 5.5,-1.0 l24.0,6.0 20.5,-2.0 l24.0,-12.5 14.5,-4.0 l10.0,-1.5 11.0,1.0 l13.0,8.0 10.0,12.5 l4.0,13.5 0.0,10.0 l-0.5,8.0 -7.0,8.5 l-6.0,5.0 -10.0,3.5 l-10.0,2.0 -22.5,0.5 l-10.0,0.0 -9.5,1.0 l-9.0,5.0 -15.5,8.5 l-13.5,7.5 -15.5,5.0 l-14.0,0.0 -11.0,-4.0 l-8.0,-9.0 -6.0,-10.5 l-3.0,-8.0 -5.5,0.0 l-12.0,6.5 -12.0,4.0 l-11.0,1.5 -12.5,-3.5 l-9.0,-7.0 -5.0,-9.5 l-1.5,-13.5 0.5,-7.5 l3.5,-4.0 4.0,-1.5 l1.5,-1.0 0.0,-1.0 l-2.0,-0.5 -5.0,-3.5 l-3.0,-8.5 -0.5,-11.5 l2.5,-6.0 6.0,-7.0 l9.0,-5.5 10.0,-2.0 l10.0,0.0 7.0,3.5 l6.0,6.0 1.5,5.0 l-0.0,2.0 -0.0,2.5 l1.0,1.5 10.0,6.0 l3.0,6.5 0.5,8.5 l-4.5,6.0 -8.0,4.5 l-11.5,1.5 -10.5,1.5 l-7.0,5.0 -13.0,2.5 l-11.5,-1.5 -8.5,-3.5 l-7.0,-4.0 -9.0,-7.0 l-5.0,-3.5 -3.0,-3.0 l-2.0,-7.0 -2.0,-7.5 l-2.5,-6.0 -2.5,-8.0 l0.5,-7.5 5.5,-6.5 l5.5,-4.0 8.0,-1.0 l8.0,4.0 4.0,4.5 l2.5,5.0 1.0,1.5 l3.0,20.0 2.0,4.5 l3.0,7.5 3.0,3.5 l5.5,4.5 7.0,4.5 l8.0,4.0 8.0,1.0 l7.5,-1.5 10.0,-5.0 l9.0,-6.5 6.5,-7.5 l5.0,-7.5 3.5,-11.0 l2.0,-5.0 2.0,-5.0 l1.5,-6.5 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = 300\n",
    "test_sample = test_set[test_index][:20]\n",
    "new_sample = test_sample.reshape((1,nx*ny))\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # get the last 20 samples (20*3 datapoints = 60)\n",
    "    yhat = loaded_model.predict(np.array([new_sample[0][-60:]]))\n",
    "    \n",
    "    # we round off the output to remove decimals\n",
    "    yhat[0][0] = round(yhat[0][0])\n",
    "    yhat[0][1] = round(yhat[0][1])\n",
    "    yhat[0][2] = round(yhat[0][2])\n",
    "    \n",
    "    #append the prediction to sample\n",
    "    new_sample = np.append(new_sample,yhat)\n",
    "\n",
    "    #to retain dimension of the sample\n",
    "    new_sample = np.array([new_sample])\n",
    "\n",
    "#since the predicted sample was flattened, reshape it back to (number of datapoints,3)\n",
    "new_sample = new_sample.reshape(int(len(new_sample[0])/3),3)\n",
    "\n",
    "print(\"Our prediction\")\n",
    "#draw the prediction\n",
    "draw_strokes(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"290.5\" version=\"1.1\" width=\"512.5\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"290.5\" width=\"512.5\" x=\"0\" y=\"0\"/><path d=\"M29.0,184.0 m-4.0,-18.5 l5.5,-23.5 17.0,-31.5 l27.5,-32.5 42.0,-31.0 l47.0,-18.5 38.0,-3.5 l24.5,9.0 11.5,19.0 l2.5,23.0 -3.5,25.0 l-8.0,16.5 -8.5,8.0 l1.5,-13.0 19.0,-24.5 l27.5,-23.0 33.0,-16.5 l28.0,-7.0 22.0,-1.0 l18.0,4.5 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M29.0,184.0 m-4.0,-18.5 l5.5,-23.5 17.0,-31.5 l27.5,-32.5 42.0,-31.0 l47.0,-18.5 38.0,-3.5 l24.5,9.0 11.5,19.0 l2.5,23.0 -3.5,25.0 l-8.0,16.5 -8.5,8.0 l1.5,-13.0 19.0,-24.5 l27.5,-23.0 33.0,-16.5 l28.0,-7.0 22.0,-1.0 l18.0,4.5 31.5,14.5 l29.5,18.5 21.5,17.5 l12.0,20.5 12.5,21.5 l9.0,29.5 2.0,18.0 l-2.0,25.0 -7.5,19.5 l-7.0,9.5 -11.5,10.0 l-20.0,7.5 -23.0,4.0 l-27.5,3.0 -40.0,2.0 l-41.0,-1.0 -27.5,-5.0 l-32.5,-7.0 -20.0,-6.0 l-24.5,-9.0 -17.5,-8.0 l-10.0,-5.5 -13.0,-6.5 l-9.0,-7.0 -9.0,-12.0 l-4.0,-10.5 -3.0,-16.5 l2.0,-14.0 4.0,-11.0 l8.0,-9.5 14.0,-9.0 l15.5,-5.0 10.5,-2.5 l14.5,1.0 14.0,2.5 l13.0,7.0 11.0,6.0 l7.0,4.5 8.0,4.0 l14.5,2.5 17.0,-0.0 l14.5,-3.0 21.0,-7.5 l10.5,-6.0 10.0,-7.0 l10.5,-7.5 6.0,-5.0 l4.0,-6.0 1.0,-8.0 l-3.5,-7.0 -8.5,-10.0 l-8.0,-6.0 -11.0,-4.0 l-11.5,-3.0 -11.5,0.0 l-10.5,3.5 -6.0,2.5 l-5.0,1.5 -11.5,-4.0 l-10.0,-1.0 -10.5,3.0 l-10.0,6.5 -5.0,6.5 l-3.0,4.0 -1.5,7.0 l-1.0,4.0 -2.5,7.0 l-8.0,6.0 -7.0,8.0 l-2.5,8.0 0.0,9.5 l4.0,7.5 7.0,5.5 l6.0,1.5 10.5,0.0 l10.0,-3.0 9.0,-6.0 l2.5,-0.0 7.5,10.5 l9.0,5.5 11.5,1.5 l10.0,-2.0 8.5,-6.0 l4.5,-8.5 5.0,-6.0 l3.0,-9.5 2.5,-2.5 l8.5,-2.5 7.0,-4.5 l6.0,-5.5 4.0,-10.0 l1.0,-11.0 -2.5,-9.5 l-6.5,-8.0 -9.5,-5.5 l-12.0,-2.5 -11.0,-0.5 l-8.5,3.0 -5.5,-2.0 l-12.0,-11.5 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = 19\n",
    "test_sample = test_set[test_index][:20]\n",
    "new_sample = test_sample.reshape((1,nx*ny))\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # get the last 20 samples (20*3 datapoints = 60)\n",
    "    yhat = loaded_model.predict(np.array([new_sample[0][-60:]]))\n",
    "    \n",
    "    # we round off the output to remove decimals\n",
    "    yhat[0][0] = round(yhat[0][0])\n",
    "    yhat[0][1] = round(yhat[0][1])\n",
    "    yhat[0][2] = round(yhat[0][2])\n",
    "    \n",
    "    #append the prediction to sample\n",
    "    new_sample = np.append(new_sample,yhat)\n",
    "\n",
    "    #to retain dimension of the sample\n",
    "    new_sample = np.array([new_sample])\n",
    "\n",
    "#since the predicted sample was flattened, reshape it back to (number of datapoints,3)\n",
    "new_sample = new_sample.reshape(int(len(new_sample[0])/3),3)\n",
    "\n",
    "print(\"Our prediction\")\n",
    "#draw the prediction\n",
    "draw_strokes(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"200.0\" version=\"1.1\" width=\"270.0\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"200.0\" width=\"270.0\" x=\"0\" y=\"0\"/><path d=\"M97.5,144.5 m4.0,-8.0 l14.5,-10.5 6.0,-0.5 l10.5,8.0 2.0,0.0 l12.5,-11.5 12.5,-5.0 l7.0,2.0 8.5,8.5 l4.5,2.0 6.5,-1.5 l15.5,-9.5 8.0,-2.0 l7.0,0.5 5.5,3.5 l9.0,-1.0 5.5,3.0 l7.5,8.5 1.0,7.0 l-1.0,6.0 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M97.5,144.5 m4.0,-8.0 l14.5,-10.5 6.0,-0.5 l10.5,8.0 2.0,0.0 l12.5,-11.5 12.5,-5.0 l7.0,2.0 8.5,8.5 l4.5,2.0 6.5,-1.5 l15.5,-9.5 8.0,-2.0 l7.0,0.5 5.5,3.5 l9.0,-1.0 5.5,3.0 l7.5,8.5 1.0,7.0 l-1.0,6.0 -2.5,4.0 l-7.0,8.0 -14.0,6.5 l-6.0,1.0 -5.5,-2.0 l-4.5,0.0 -16.5,10.5 l-8.5,3.0 -11.0,-1.0 l-5.5,-3.5 -5.0,-7.5 l-7.0,2.5 -10.5,2.5 l-12.5,-0.5 -6.0,-5.0 l-4.5,-7.5 0.5,-7.5 l1.5,-4.5 5.0,-3.0 l3.5,0.0 -1.0,0.5 l-3.5,-3.0 -2.0,-6.5 l0.0,-8.5 2.5,-5.5 l6.5,-5.5 8.0,-3.0 l9.0,-1.5 7.0,2.0 l5.0,4.0 3.5,7.5 l3.0,6.5 2.0,2.0 l4.5,4.0 2.5,4.5 l2.0,7.0 -1.0,6.5 l-6.0,6.0 -7.5,3.5 l-8.0,1.0 -8.0,-1.5 l-7.0,-3.0 -6.0,-4.0 l-4.5,1.5 -9.5,6.0 l-11.0,1.5 -8.5,-3.5 l-4.5,-5.0 -3.0,-7.5 l-5.5,0.0 -8.0,3.5 l-8.5,5.5 -8.0,3.5 l-10.5,-0.5 -9.0,-6.0 l-5.0,-7.0 -3.0,-10.0 l0.5,-10.5 4.5,-6.5 l5.0,-1.0 2.0,2.5 l-3.5,3.5 -6.5,0.5 l-5.0,-2.5 -5.5,-8.0 l-1.5,-10.0 2.5,-8.5 l5.5,-7.0 7.0,-4.0 l7.5,-1.0 5.0,2.0 l1.5,1.0 6.0,-0.5 l8.0,-2.5 12.5,-7.5 l9.5,-3.0 11.0,0.0 l6.5,4.0 4.5,5.0 l4.5,8.0 4.0,4.0 l5.0,2.5 7.0,0.5 l9.5,-3.5 8.5,-5.0 l6.5,-4.5 7.0,-3.5 l6.5,-3.5 7.0,-8.0 l3.5,-9.0 1.5,-9.5 l-2.0,-6.5 -6.0,-5.5 l-10.5,-3.0 -6.5,1.0 l-2.5,-0.5 -3.0,-5.5 l-7.5,-4.5 -9.5,0.0 l-6.0,3.0 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = 200\n",
    "test_sample = test_set[test_index][:20]\n",
    "new_sample = test_sample.reshape((1,nx*ny))\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # get the last 20 samples (20*3 datapoints = 60)\n",
    "    yhat = loaded_model.predict(np.array([new_sample[0][-60:]]))\n",
    "    \n",
    "    # we round off the output to remove decimals\n",
    "    yhat[0][0] = round(yhat[0][0])\n",
    "    yhat[0][1] = round(yhat[0][1])\n",
    "    yhat[0][2] = round(yhat[0][2])\n",
    "    \n",
    "    #append the prediction to sample\n",
    "    new_sample = np.append(new_sample,yhat)\n",
    "\n",
    "    #to retain dimension of the sample\n",
    "    new_sample = np.array([new_sample])\n",
    "\n",
    "#since the predicted sample was flattened, reshape it back to (number of datapoints,3)\n",
    "new_sample = new_sample.reshape(int(len(new_sample[0])/3),3)\n",
    "\n",
    "print(\"Our prediction\")\n",
    "#draw the prediction\n",
    "draw_strokes(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max depth of each tree in the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[78, 82, 71, 71, 79, 75, 72, 76, 77, 73]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the max depth of each tree in the model\")\n",
    "[estimator.tree_.max_depth for estimator in loaded_model.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

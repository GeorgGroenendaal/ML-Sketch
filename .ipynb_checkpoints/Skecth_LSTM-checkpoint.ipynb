{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions to work with svg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for draw_strokes\n",
    "def get_bounds(data, factor):\n",
    "  min_x = 0\n",
    "  max_x = 0\n",
    "  min_y = 0\n",
    "  max_y = 0\n",
    "    \n",
    "  abs_x = 0\n",
    "  abs_y = 0\n",
    "  for i in xrange(len(data)):\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    abs_x += x\n",
    "    abs_y += y\n",
    "    min_x = min(min_x, abs_x)\n",
    "    min_y = min(min_y, abs_y)\n",
    "    max_x = max(max_x, abs_x)\n",
    "    max_y = max(max_y, abs_y)\n",
    "    \n",
    "  return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=2, svg_filename = 'sample.svg'):\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(0,20):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"red\"\n",
    "  stroke_width = 2\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  for i in xrange(20,len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=15.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)\n",
    "#test_set = np.load(data_dir, encoding='latin1', allow_pickle=True)\n",
    "# get a sample drawing from the test set, and render it to .svg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"159.0\" version=\"1.1\" width=\"245.5\"><defs/><rect fill=\"white\" height=\"159.0\" width=\"245.5\" x=\"0\" y=\"0\"/><path d=\"M65.0,110.5 m-4.5,-10.5 l-4.0,-23.0 -1.0,-24.0 l2.0,-2.5 6.5,-2.0 l4.5,4.0 7.5,13.5 l3.0,-12.5 8.0,-14.0 l9.5,-7.5 8.5,-3.0 l17.5,-4.0 7.5,10.0 l2.0,5.5 0.5,13.5 l8.0,-11.0 18.0,-11.0 l14.0,-1.5 28.5,0.0 l3.5,6.0 \" fill=\"none\" stroke=\"red\" stroke-width=\"2\"/><path d=\"M65.0,110.5 m-4.5,-10.5 l-4.0,-23.0 -1.0,-24.0 l2.0,-2.5 6.5,-2.0 l4.5,4.0 7.5,13.5 l3.0,-12.5 8.0,-14.0 l9.5,-7.5 8.5,-3.0 l17.5,-4.0 7.5,10.0 l2.0,5.5 0.5,13.5 l8.0,-11.0 18.0,-11.0 l14.0,-1.5 28.5,0.0 l3.5,6.0 1.0,13.0 l-1.0,4.0 -7.0,4.5 l1.0,2.5 21.0,17.0 l1.0,11.5 -3.5,8.5 l-9.0,13.0 -9.5,7.0 l-4.0,1.0 -1.0,-2.5 l0.5,-14.0 -1.5,8.5 l-3.5,6.0 -5.0,7.0 l-8.0,6.5 -11.5,4.0 l-6.0,0.0 -3.5,-2.5 l-2.5,-4.0 0.0,-15.0 l2.0,-6.5 -6.5,9.5 l-14.5,9.5 -23.5,6.5 l-10.0,-1.0 -1.0,-7.0 l1.0,-3.0 4.5,-4.0 l11.5,-7.5 -2.0,4.5 l-9.0,4.0 -20.0,2.0 l-14.0,-1.5 -0.5,-6.0 l6.5,-3.0 -0.5,2.5 l-6.0,5.5 -7.5,2.5 l-32.5,0.0 -3.5,-2.0 l-2.0,-5.0 0.0,-10.5 l7.5,-4.5 15.0,0.0 l6.5,3.0 -1.5,-2.0 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Focus on cloud for the begining\n",
    "data_dir = 'cloud.npz'\n",
    "\n",
    "load_data = np.load(data_dir, encoding='latin1', allow_pickle=True) #specific to python3\n",
    "train_set = load_data['train']\n",
    "valid_set = load_data['valid']\n",
    "test_set = load_data['test']\n",
    "\n",
    "print (len(train_set))\n",
    "print (len(valid_set))\n",
    "print (len(test_set))\n",
    "\n",
    "draw_strokes(random.choice(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_window(input_data: np.array, window_size: int) -> np.array:\n",
    "    data_len = len(input_data)\n",
    "    result = np.zeros((data_len-window_size+1, window_size, *input_data.shape[1:]))\n",
    "    for i in range(data_len):\n",
    "        if i+window_size <= data_len:\n",
    "            result[i] = input_data[i:i+window_size]\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_window_on_multiple_samples(input_data: np.array, window_size: int, normalized = False) -> np.array:\n",
    "    \"\"\"\n",
    "    Similar to create_window, but now can take multiple samples, will output in one\n",
    "    giant windowed np.array.\n",
    "    \"\"\"\n",
    "    windowed_data = []\n",
    "    scaler = MinMaxScaler()\n",
    "    for i, sample in enumerate(input_data):\n",
    "        win = create_window(sample[:,:2], window_size)\n",
    "        \n",
    "        # Normalize the data\n",
    "        if normalized:\n",
    "            win = normalise_windows(win)\n",
    "            \n",
    "        windowed_data.append(win)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Now at {i}\")\n",
    "            clear_output(wait=True)\n",
    "    result = np.concatenate(windowed_data)\n",
    "#     print(f\"result = {result} \\t winddata = {windowed_data}\")\n",
    "    print(f\"Done processing {i} samples, total of {result.shape[0]} windows and {result.shape[0] * result.shape[1]} datapoints\")\n",
    "    return np.concatenate(result)\n",
    "\n",
    "\n",
    "def split_train_test(input_data: List) -> Tuple[np.array, np.array]:\n",
    "    return input_data[:,:-1], input_data[:,-1]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    # A support function to normalize a dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        scaled = scaler.fit_transform(window)\n",
    "        normalised_data.append(scaled)\n",
    "    return np.concatenate(normalised_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing 499 samples, total of 186704 windows and 373408 datapoints\n"
     ]
    }
   ],
   "source": [
    "x = create_window_on_multiple_samples(train_set[:500], 7, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f89df7df9d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X = np.asarray(X).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Y = np.asarray(Y).astype('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-7ef190fef21c>\u001b[0m in \u001b[0;36msplit_train_test\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalise_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# x\n",
    "X, Y = split_train_test(x)\n",
    "# X\n",
    "# X = np.asarray(X).astype('float32')\n",
    "# Y = np.asarray(Y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 186704, 50)        10600     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 186704, 50)        20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 186704, 50)        0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 186704, 50)        20200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 186704, 50)        0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,251\n",
      "Trainable params: 71,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-176ca9de4672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/ali/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Initialize LSTM\n",
    "model = Sequential()\n",
    "# print (train_set[3].shape)\n",
    "model.add(LSTM(units=50, return_sequences=True,\n",
    "     input_shape=(X.shape[0], 2)))\n",
    "\n",
    "# Adding a second LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # Adding a fourth LSTM layer and Dropout regularisation\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\n",
    "print(model.summary())\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs = 200)\n",
    "# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9b4c02fe1cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plt.ylabel('loss'); plt.xlabel('epoch')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit LSTM model\n",
    "# history = model.fit(X, Y, epochs = 100, batch_size = 50, verbose = 1)\n",
    "# plt.figure()\n",
    "# plt.ylabel('loss'); plt.xlabel('epoch')\n",
    "plt.semilogy(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X= np.empty([0,S_reg*3])\n",
    "# line= np.array([])\n",
    "# Y=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #warning: x goes into floating...\n",
    "# for data in test_set:\n",
    "#     i=20\n",
    "#     while i <= (len(data)-1):\n",
    "#         line= np.array([])\n",
    "#         for j in range (S_reg):\n",
    "#             line = np.concatenate((line, data[i-S_reg+j]), 0)\n",
    "#         #print(X,line)\n",
    "#         X = np.vstack((X, line))\n",
    "#         Y = np.concatenate((Y, data[i]), 0) #to change\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=Y.reshape((int(len(Y)/3), 3)) #to change\n",
    "# X=X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv=np.linalg.inv(np.dot(X,X.T)+0.01*np.identity(S_reg*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W=np.dot(np.dot(inv,X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test in range (0,100):\n",
    "#     ini=np.array([])\n",
    "#     for i in range(20):\n",
    "#         ini=np.concatenate((ini, train_set[test][i]), 0)\n",
    "#     draw=train_set[test][0:20]\n",
    "#     for i in range (300):\n",
    "#         draw=np.vstack((draw, np.dot(W.T,ini)))\n",
    "#         ini=np.concatenate((ini, draw[-1]), 0)\n",
    "#         ini = np.delete(ini, [0,1,2])\n",
    "#     draw[:, 2]=0 # I do not take into account the different strokes\n",
    "#     draw_strokes(draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echo State network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for count,sample in enumerate(train_set[0:2500]):\n",
    "#     if count==0:\n",
    "#         X_train=sample\n",
    "#     else:\n",
    "#         X_train = np.vstack((X_train,sample))\n",
    "#     train_set[count]=np.tanh(np.delete(sample, 2, axis=1)/100) #trick for not caring about different strokes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data \n",
    "# in \"plain\" scientific Python.\n",
    "# from https://mantas.info/code/simple_esn/\n",
    "# (c) 2012-2020 Mantas LukoÅ¡eviÄius\n",
    "# Distributed under MIT license https://opensource.org/licenses/MIT\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import linalg \n",
    "# # numpy.linalg is also an option for even fewer dependencies\n",
    "\n",
    "# # load the data\n",
    "# data = train_set[0:2000]\n",
    "# trainLen = len(X_train) \n",
    "# testLen = len(X_train) \n",
    "# initLen = 0 #Warning higly reduced\n",
    "\n",
    "\n",
    "# # generate the ESN reservoir\n",
    "# inSize = outSize = 2\n",
    "# resSize = 1000\n",
    "# L_a = [0.3,1,5] # leaking rate\n",
    "# np.random.seed(42)\n",
    "# L_Win = [(np.random.rand(resSize,1+inSize) - 0.5) *i for i in [0.1,1,2]]\n",
    "# label_Win = [0.1,1,2]\n",
    "\n",
    "# W = np.random.rand(resSize,resSize) - 0.5 \n",
    "# # normalizing and setting spectral radius (correct, slow):\n",
    "# print('Computing spectral radius...')\n",
    "# rhoW = max(abs(linalg.eig(W)[0]))\n",
    "# print('done.')\n",
    "# L_W = [W*i / rhoW for i in [0.75,1,1.25]]\n",
    "# label_W = [0.75,1,1.5]\n",
    "\n",
    "# # allocated memory for the design (collected states) matrix\n",
    "# X = np.zeros((1+inSize+resSize,trainLen-(initLen+1)*len(data)))\n",
    "# Yt = np.zeros((outSize,trainLen-(initLen+1)*len(data)))\n",
    "\n",
    "# # set the corresponding target matrix directly\n",
    "# #Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# print(\"run reservoir\")\n",
    "# L_XXT=[]\n",
    "# L_XYT=[]\n",
    "# # run the reservoir with the data and collect X\n",
    "# i=0\n",
    "# for W in L_W:\n",
    "#      for Win in L_Win:\n",
    "#         for a in L_a:\n",
    "#             i+=1\n",
    "#             print(i)\n",
    "#             # allocated memory for the design (collected states) matrix\n",
    "#             X = np.zeros((1+inSize+resSize,trainLen-(initLen+1)*len(data)))\n",
    "#             Yt = np.zeros((outSize,trainLen-(initLen+1)*len(data)))\n",
    "#             for sample in data:\n",
    "#                 x = np.zeros((resSize,1))\n",
    "#                 count_global=0\n",
    "#                 for count,u in enumerate(sample):\n",
    "#                     u=np.array([u]).T\n",
    "#                     #print(np.vstack((1,u)))\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     if count >= initLen:\n",
    "#                         count_global += 1\n",
    "#                         X[:,count_global] = np.vstack((1,u,x))[:,0]\n",
    "#                         if count >= initLen+1:\n",
    "#                             Yt[:,count_global-1] = np.vstack((u))[:,0]\n",
    "#                     if count == len(sample)-2:\n",
    "#                         Yt[:,count_global-1] = np.vstack((u))[:,0]\n",
    "#                         break\n",
    "#             L_XXT.append(np.dot(X,X.T))\n",
    "#             L_XYT.append(np.dot(X,Yt.T))\n",
    "                \n",
    "# print(\"train reservoir\")\n",
    "# # train the output by ridge regression\n",
    "# Wout_list=[]\n",
    "# count=0\n",
    "# for w,W in zip(label_W,L_W):\n",
    "#     for win,Win in zip(label_Win,L_Win):\n",
    "#         for a in L_a:\n",
    "#             XXT=L_XXT[count]\n",
    "#             XYT=L_XYT[count]\n",
    "#             count=+1\n",
    "#             for i in range(8):\n",
    "#                 reg = 1^-i  # regularization coefficient\n",
    "#                 # direct equations from texts:\n",
    "#                 #X_T = X.T\n",
    "#                 #Wout = np.dot( np.dot(Yt,X_T), linalg.inv( np.dot(X,X_T) + \\\n",
    "#                 #    reg*np.eye(1+inSize+resSize) ) )\n",
    "#                 # using scipy.linalg.solve:\n",
    "#                 Wout = linalg.solve( XXT + reg*np.eye(1+inSize+resSize), \n",
    "#                     XYT ).T\n",
    "#                 Wout_list.append([Wout,W,str(w),Win,str(win),a,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"Nz1000_data2000_norm.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Wout_list, fp)\n",
    "\n",
    "with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Wout_list = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import linalg as LA\n",
    "# L_mse=[]\n",
    "\n",
    "# for count,Wout in enumerate(Wout_list):\n",
    "#     Wout,W,w,Win,win,a,i=Wout\n",
    "#     for number in range (500):\n",
    "#         Y = np.zeros((outSize, len(data[number])))\n",
    "#         X = np.zeros((resSize, len(data[number])))\n",
    "#         u = np.array([data[number][0]]).T\n",
    "#         x = np.zeros((resSize,1))\n",
    "#         mse_ini=0\n",
    "#         mse_fill=0\n",
    "#         for t in range(len(data[number])):\n",
    "#             if t <= 15:\n",
    "#                 u = np.array([data[number][t]]).T\n",
    "#                 x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                 y = np.dot(Wout, np.vstack((1,u,x)))\n",
    "#                 #y=np.array([y]).T\n",
    "#                 Y[:,t] = y[:,0]\n",
    "#                 mse_ini += LA.norm(y[:,0]-data[number][t+1])\n",
    "#             else:\n",
    "#                 x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                 y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#                 u = y\n",
    "#                 #print(y)\n",
    "#                 #y=np.array([y]).T\n",
    "#                 Y[:,t] = y[:,0]\n",
    "#                 # generative mode:\n",
    "#                 if t < len(data[number])-2:\n",
    "#                     mse_fill += LA.norm(y[:,0]-data[number][t+1])\n",
    "#             X[:,t]=np.array([x]).T[:,0]\n",
    "\n",
    "            \n",
    "#         mse_ini = mse_ini/(15)\n",
    "#         mse_fill = mse_fill/len(data[number]-15)\n",
    "\n",
    "#         row = {'mse_ini' : mse_ini, 'mse_fill' : mse_fill, 'w' : float(w), 'win' : float(win),'a' : float(a),'i' : float(i),'number' : number}\n",
    "#     L_mse.append(row)       \n",
    "# df = pd.DataFrame(L_mse)\n",
    "# df.to_pickle(\"mse(Nz1000_data2000_norm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To plot\n",
    "# for count,Wout in enumerate(Wout_list):\n",
    "#     Wout,W,w,Win,win,a,i=Wout\n",
    "#     if (w==str(1.50)) & (win==str(2)) & (a==1) & (i==3.0):\n",
    "#         for number in range (0,5):\n",
    "#             Y = np.zeros((outSize, len(data[number])))\n",
    "#             X = np.zeros((resSize, len(data[number])))\n",
    "#             u = np.array([data[number][0]]).T\n",
    "#             x = np.zeros((resSize,1))\n",
    "#             mse_ini=0\n",
    "#             mse_fill=0\n",
    "#             for t in range(len(data[number])):\n",
    "#                 if t <= 20:\n",
    "#                     u = np.array([data[number][t]]).T\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     y = np.dot(Wout, np.vstack((1,u,x)))\n",
    "#                     #y=np.array([y]).T\n",
    "#                     Y[:,t] = y[:,0]\n",
    "#                     mse_ini += LA.norm(y[:,0]-data[number][t+1])\n",
    "#                 else:\n",
    "#                     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#                     y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#                     u = y\n",
    "\n",
    "#                     Y[:,t] = y[:,0]\n",
    "#                     # generative mode:\n",
    "#                     if t < len(data[number])-2:\n",
    "#                         mse_fill += LA.norm(y[:,0]-data[number][t+1])\n",
    "#                 X[:,t]=np.array([x]).T[:,0]\n",
    "                \n",
    "#             N = 2\n",
    "#             b = np.zeros((len(data[number]),N+1))\n",
    "#             b[:,:-1] = Y.T\n",
    "#             #print(Y.T)\n",
    "#             #print(b)\n",
    "#             draw_strokes(b,factor=2,svg_filename = str(number)+'sample.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         N = 2\n",
    "#         a = np.random.rand(N,N)\n",
    "#         b = np.zeros((N,N+1))\n",
    "#         b[:,:-1] = a\n",
    "#         b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_strokes(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data \n",
    "# in \"plain\" scientific Python.\n",
    "# from https://mantas.info/code/simple_esn/\n",
    "# (c) 2012-2020 Mantas LukoÅ¡eviÄius\n",
    "# Distributed under MIT license https://opensource.org/licenses/MIT\n",
    "# \"\"\"\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import linalg \n",
    "# # numpy.linalg is also an option for even fewer dependencies\n",
    "\n",
    "# # load the data\n",
    "# trainLen = 2000\n",
    "# testLen = 2000\n",
    "# initLen = 100\n",
    "# data = np.loadtxt('MackeyGlass_t17.txt')\n",
    "\n",
    "# # plot some of it\n",
    "# plt.figure(10).clear()\n",
    "# plt.plot(data[:1000])\n",
    "# plt.title('A sample of data')\n",
    "\n",
    "# # generate the ESN reservoir\n",
    "# inSize = outSize = 1\n",
    "# resSize = 1000\n",
    "# a = 0.3 # leaking rate\n",
    "# np.random.seed(42)\n",
    "# Win = (np.random.rand(resSize,1+inSize) - 0.5) * 1\n",
    "# W = np.random.rand(resSize,resSize) - 0.5 \n",
    "# # normalizing and setting spectral radius (correct, slow):\n",
    "# print('Computing spectral radius...')\n",
    "# rhoW = max(abs(linalg.eig(W)[0]))\n",
    "# print('done.')\n",
    "# W *= 1.25 / rhoW\n",
    "\n",
    "# # allocated memory for the design (collected states) matrix\n",
    "# X = np.zeros((1+inSize+resSize,trainLen-initLen))\n",
    "# # set the corresponding target matrix directly\n",
    "# Yt = data[None,initLen+1:trainLen+1] \n",
    "\n",
    "# # run the reservoir with the data and collect X\n",
    "# x = np.zeros((resSize,1))\n",
    "# for t in range(trainLen):\n",
    "#     u = data[t]\n",
    "#     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#     if t >= initLen:\n",
    "#         X[:,t-initLen] = np.vstack((1,u,x))[:,0]\n",
    "    \n",
    "# # train the output by ridge regression\n",
    "# reg = 1e-8  # regularization coefficient\n",
    "# # direct equations from texts:\n",
    "# #X_T = X.T\n",
    "# #Wout = np.dot( np.dot(Yt,X_T), linalg.inv( np.dot(X,X_T) + \\\n",
    "# #    reg*np.eye(1+inSize+resSize) ) )\n",
    "# # using scipy.linalg.solve:\n",
    "# Wout = linalg.solve( np.dot(X,X.T) + reg*np.eye(1+inSize+resSize), \n",
    "#     np.dot(X,Yt.T) ).T\n",
    "\n",
    "# # run the trained ESN in a generative mode. no need to initialize here, \n",
    "# # because x is initialized with training data and we continue from there.\n",
    "# Y = np.zeros((outSize,testLen))\n",
    "# u = data[trainLen]\n",
    "# for t in range(testLen):\n",
    "#     x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) )\n",
    "#     y = np.dot( Wout, np.vstack((1,u,x)) )\n",
    "#     Y[:,t] = y\n",
    "#     # generative mode:\n",
    "#     u = y\n",
    "#     ## this would be a predictive mode:\n",
    "#     #u = data[trainLen+t+1] \n",
    "\n",
    "# # compute MSE for the first errorLen time steps\n",
    "# errorLen = 500\n",
    "# mse = sum( np.square( data[trainLen+1:trainLen+errorLen+1] - \n",
    "#     Y[0,0:errorLen] ) ) / errorLen\n",
    "# print('MSE = ' + str( mse ))\n",
    "    \n",
    "# # plot some signals\n",
    "# plt.figure(1).clear()\n",
    "# plt.plot( data[trainLen+1:trainLen+testLen+1], 'g' )\n",
    "# plt.plot( Y.T, 'b' )\n",
    "# plt.title('Target and generated signals $y(n)$ starting at $n=0$')\n",
    "# plt.legend(['Target signal', 'Free-running predicted signal'])\n",
    "\n",
    "# plt.figure(2).clear()\n",
    "# plt.plot( X[0:20,0:200].T )\n",
    "# plt.title(r'Some reservoir activations $\\mathbf{x}(n)$')\n",
    "\n",
    "# plt.figure(3).clear()\n",
    "# plt.bar( np.arange(1+inSize+resSize), Wout[0].T )\n",
    "# plt.title(r'Output weights $\\mathbf{W}^{out}$')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_i=df\n",
    "# df_i= df.groupby(['w','win','a',\"i\"])['mse_fill'].mean().reset_index()\n",
    "# df_i[df_i.mse_fill<0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=300)\n",
    "# ax = fig.gca(projection='3d')\n",
    "# for i in range (8):\n",
    "\n",
    "#     df_i=df[df.i == i ]\n",
    "#     df_i= df_i.groupby(['w','win','a'])['mse_fill'].mean().reset_index()\n",
    "#     xs = list(df_i['w'])\n",
    "#     ys = list(df_i['win']+0.05*i)\n",
    "#     zs = list(df_i['a'])\n",
    "#     ss = list(df_i['mse_fill'])\n",
    "#     #print(xs)\n",
    "    \n",
    "#     ax.set_xlabel('w')\n",
    "#     ax.set_ylabel('win')\n",
    "#     ax.set_zlabel('a')\n",
    "\n",
    "#     surf=ax.scatter3D(xs, ys, zs, c=ss,vmin=0,vmax=0.5,s=20)#, lw=0, s=100,alpha=1,marker=\"o\",vmin=vmin,vmax=vmax)\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "# plt.show()\n",
    "# plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212.003px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

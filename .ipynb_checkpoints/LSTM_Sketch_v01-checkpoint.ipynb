{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"cloud.npz\", encoding=\"latin1\", allow_pickle=True)\n",
    "train = data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for draw_strokes\n",
    "def get_bounds(data, factor):\n",
    "    min_x = 0\n",
    "    max_x = 0\n",
    "    min_y = 0\n",
    "    max_y = 0\n",
    "\n",
    "    abs_x = 0\n",
    "    abs_y = 0\n",
    "    for i in xrange(len(data)):\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        abs_x += x\n",
    "        abs_y += y\n",
    "        min_x = min(min_x, abs_x)\n",
    "        min_y = min(min_y, abs_y)\n",
    "        max_x = max(max_x, abs_x)\n",
    "        max_y = max(max_y, abs_y)\n",
    "    \n",
    "    return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=2, svg_filename = 'sample.svg'):\n",
    "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "    lift_pen = 1\n",
    "    abs_x = 25 - min_x \n",
    "    abs_y = 25 - min_y\n",
    "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "    command = \"m\"\n",
    "    for i in xrange(0,20):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command+str(x)+\",\"+str(y)+\" \"\n",
    "    the_color = \"red\"\n",
    "    stroke_width = 2\n",
    "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "    for i in xrange(20,len(data)):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i,0])/factor\n",
    "        y = float(data[i,1])/factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command+str(x)+\",\"+str(y)+\" \"\n",
    "    the_color = \"black\"\n",
    "    stroke_width = 1\n",
    "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "    dwg.save()\n",
    "    display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=15.0):\n",
    "    \n",
    "    def get_start_and_end(x):\n",
    "        x = np.array(x)\n",
    "        x = x[:, 0:2]\n",
    "        x_start = x[0]\n",
    "        x_end = x.sum(axis=0)\n",
    "        x = x.cumsum(axis=0)\n",
    "        x_max = x.max(axis=0)\n",
    "        x_min = x.min(axis=0)\n",
    "        center_loc = (x_max+x_min)*0.5\n",
    "        return x_start-center_loc, x_end\n",
    "  \n",
    "    x_pos = 0.0\n",
    "    y_pos = 0.0\n",
    "    result = [[x_pos, y_pos, 1]]\n",
    "    \n",
    "    for sample in s_list:\n",
    "        s = sample[0]\n",
    "        grid_loc = sample[1]\n",
    "        grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "        grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "        start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "        loc_x = start_loc[0]\n",
    "        loc_y = start_loc[1]\n",
    "        new_x_pos = grid_x+loc_x\n",
    "        new_y_pos = grid_y+loc_y\n",
    "        result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "        result += s.tolist()\n",
    "        result[-1][2] = 1\n",
    "        x_pos = new_x_pos+delta_pos[0]\n",
    "        y_pos = new_y_pos+delta_pos[1]\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_window(input_data: np.array, window_size: int) -> np.array:\n",
    "    data_len = len(input_data)\n",
    "    result = np.zeros((data_len-window_size+1, window_size, *input_data.shape[1:]))\n",
    "    for i in range(data_len):\n",
    "        if i+window_size <= data_len:\n",
    "            result[i] = input_data[i:i+window_size]\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_window_on_multiple_samples(input_data: np.array, window_size: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Similar to create_window, but now can take multiple samples, will output in one\n",
    "    giant windowed np.array.\n",
    "    \"\"\"\n",
    "    windowed_data = []\n",
    "    for i, sample in enumerate(input_data):\n",
    "        windowed_data.append(create_window(sample[:,:2], window_size))\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Now at {i}\")\n",
    "            clear_output(wait=True)\n",
    "    result = np.concatenate(windowed_data)\n",
    "    print(f\"Done processing {i} samples, total of {result.shape[0]} windows and {result.shape[0] * result.shape[1]} datapoints\")\n",
    "    return np.concatenate(windowed_data)\n",
    "\n",
    "\n",
    "def split_train_test(input_data: List) -> Tuple[np.array, np.array]:\n",
    "#     return input_data[:,0:-1], input_data[:,-1]\n",
    "    return input_data[:,:-1], input_data[:,-1]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    # A support function to normalize a dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    normalised_data = []\n",
    "    for i, window in enumerate(window_data):\n",
    "        scaled = scaler.fit_transform(window)\n",
    "        normalised_data.append(scaled)\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Now at {i}\")\n",
    "    return np.concatenate(normalised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing 99 samples, total of 3903 windows and 78060 datapoints\n"
     ]
    }
   ],
   "source": [
    "x = create_window_on_multiple_samples(train[:100], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_n = normalise_windows(x[:5000])\n",
    "# normalise_windows(x)\n",
    "# print(f\" x = {len(x)} \\t train = {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = split_train_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3903, 19, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shape, nx, ny = X.shape\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 3903, 10)          520       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3903, 2)           22        \n",
      "=================================================================\n",
      "Total params: 542\n",
      "Trainable params: 542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Initialize LSTM\n",
    "model = Sequential()\n",
    "# print (train_set[3].shape)\n",
    "model.add(LSTM(units=10, return_sequences=True,\n",
    "     input_shape=(X.shape[0], 2)))\n",
    "\n",
    "# Adding a second LSTM layer and Dropout regularisation\n",
    "# model.add(LSTM(units = 50, return_sequences = True))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and Dropout regularisation\n",
    "# model.add(LSTM(units = 10, return_sequences = True))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Adding a fourth LSTM layer and Dropout regularisation\n",
    "# model.add(LSTM(units = 10))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3903, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3903, 2), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 19, 2).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3903, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3903, 2), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 19, 2).\n",
      "3903/3903 - 13s - loss: 979.5454\n",
      "Epoch 2/100\n",
      "3903/3903 - 12s - loss: 969.5258\n",
      "Epoch 3/100\n",
      "3903/3903 - 12s - loss: 960.3857\n",
      "Epoch 4/100\n",
      "3903/3903 - 12s - loss: 951.1368\n",
      "Epoch 5/100\n",
      "3903/3903 - 13s - loss: 944.0785\n",
      "Epoch 6/100\n",
      "3903/3903 - 12s - loss: 937.5091\n",
      "Epoch 7/100\n",
      "3903/3903 - 12s - loss: 930.4607\n",
      "Epoch 8/100\n",
      "3903/3903 - 11s - loss: 928.5616\n",
      "Epoch 9/100\n",
      "3903/3903 - 11s - loss: 927.1063\n",
      "Epoch 10/100\n",
      "3903/3903 - 11s - loss: 919.8511\n",
      "Epoch 11/100\n",
      "3903/3903 - 11s - loss: 917.8271\n",
      "Epoch 12/100\n",
      "3903/3903 - 12s - loss: 917.9390\n",
      "Epoch 13/100\n",
      "3903/3903 - 12s - loss: 914.6411\n",
      "Epoch 14/100\n",
      "3903/3903 - 12s - loss: 914.3954\n",
      "Epoch 15/100\n",
      "3903/3903 - 12s - loss: 910.4819\n",
      "Epoch 16/100\n",
      "3903/3903 - 12s - loss: 912.2193\n",
      "Epoch 17/100\n",
      "3903/3903 - 12s - loss: 909.6640\n",
      "Epoch 18/100\n",
      "3903/3903 - 12s - loss: 907.0003\n",
      "Epoch 19/100\n"
     ]
    }
   ],
   "source": [
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# history = model.fit(X, Y, epochs=10, validation_data=(test_set, valid_set), shuffle=False)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=100, batch_size=1, verbose=2)\n",
    "# history = model.fit(X, Y, epochs = 100)\n",
    "\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "# pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-6aa42236fe9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdraw_strokes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-ccbd6038bc48>\u001b[0m in \u001b[0;36mdraw_strokes\u001b[0;34m(data, factor, svg_filename)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mlift_pen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mthe_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"red\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "ts = model.predict(X[:20])\n",
    "ts.shape\n",
    "draw_strokes(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
